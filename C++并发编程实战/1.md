# C++并发编程实战

## 1 简介

+ 为什么使用并发?  
分离关注点、性能提升  

+ 分离关注点：归类相关代码，隔离无关代码，使程序更易于理解和测试，因此所含缺陷很可能更少（划分业务），例如一个线程负责UI，一个线程负责数据处理。  
为了实现这种目的，线程的实际数量便与CPU既有的内核数量无关，因为用线程分离关注点的依据是设计理念，不以增加运算吞吐量为目的。

+ 性能提升：任务并行（单一任务分解成多个部分）、数据并行（线程对数据不同部分采取同样操作）

+ 每个线程拥有专有的内存区域：栈和堆数据段

## 2 线程管控

+ 调用构造函数的语法有可能与函数声明相同。遇到这种情况，编译器就会将其解释成函数声明，而不是定义对象
+ `std::thread` : 启动线程，接受所有可调用对象（函数指针、函数对象、lambda表达式  
+ `join()` 等待线程结束，只要调用了join()，隶属于该线程的任何存储空间即会因此清除，std::thread对象遂不再关联到已结束的线程。
+ `detach()` 不等待线程结束，在thread对象析构后，线程仍然继续执行
+ 在`std::thread`对象销毁前，必须调用`join()` or `detach()`
+ 异常发生时，利用RAII保证`join()`被正确调用

```C++
class thread_guard
{
    ...
    explicit thread_guard(std::thread& _t) : t(_t) {}

    ~thread_guard()
    {
        if (t.joinable())
        {
            t.join();
        }
    }
}
```

+ 传递参数：只需要向thread的构造函数中传入参数即可 `thread(func, arg1, arg2)`
+ 参数会按照默认方式复制到线程内部的存储空间，然后这些副本以右值的形式传递给新线程上的函数
+ 如果想要给函数传入引用，则需要给参数加上`std::ref()`包装`std::thread t(func, std::ref(arg));`
+ `std::thread`只支持移动，不支持复制，可以利用移动语意转移线程所有权
+ `std::jthread` 实现了上述`thread_guard`的功能，即在`thread`销毁时，自动调用join()
+ `std::thread::hardware_concurrency()` 返回可真正并发的线程数量
+ `std::thread::id` 线程id

## 3 线程间共享数据

+ `std::mutex`：互斥锁，包含共享数据
+ `std::lock_guard`：为互斥量自动加锁解锁，构造函数中加锁，析构函数中解锁

如何防止死锁：

+ 始终按相同的顺序对多个互斥量加锁
+ `std::lock()`：同时获取多个锁，要么全部获得，要么全部没获得

```C++
    void swap(X& lhs, X& rhs)
    {
        if (&lhs == &rhs) return;
        std::lock(lhs.m, rhs.m);
        // std::adopt_lock表示传入构造函数的互斥量已经加锁，不需要在构造函数中加锁
        std::lock_guard lockl(lhs.m, std::adopt_lock);
        std::lock_guard lockr(rhs.m, std::adopt_lock);
        swap(lhs.data, rhs.data);
    }
```

+ `std::scoped_lock`：功能同上，但是会在作用域结束后自动解锁

```C++
   void swap(X& lhs, X& rhs)
   {
        if (&lhs == &rhs) return;
        std::scoped_lock guard(lhs.m, rhs.m);
        swap(lhs.data, rhs.data);
   }
```

+ 避免嵌套锁：假如已经持有锁，就不要试图获取第二个锁。
+ 一旦持有锁，就避免调用用户提供的接口。
+ 使用固定的顺序获取锁
+ 按层级加锁 ：  
  每个锁有自己的层级编号，只允许先锁住高层级，再锁住低层级。这样限定了加锁次序。  
  只要两个层级锁都位于相同层级，我们便无法一并持有。
+ `thread_local`：用于声明线程局部存储的变量，C++11引入，被声明为`thread_local`的变量，在每个线程中会有一个独立的副本。
+ `std::unique_lock<>` 与`lock_guard<>`功能相同，但是更加灵活，可以在构造时不占有锁，也可以转移锁的所有权，但是灵活性也会带来更大的存储空间和性能消耗，所以非必要情况，一般推荐使用`lock_guard`
+ 按适合的粒度加锁

保护共享数据的其他工具  

+ 仅在初始化过程中保护共享数据，例如单例的创建、数据延迟初始化  
  a. `std::call_once()`: 保证代码只会执行一次，线程安全
  b. 静态数据的初始化是线程安全的

+ 读写锁  
  a. `std::shared_mutex`: 支持多个线程同时读，但是读写互斥，同时只能有一个线程写  
  b. 读操作只需获取共享锁: `std::shared_lock<>`  
  c. 写操作需要获取排他锁: `std::lock_guard<>`  

+ 递归锁  
  a. `std::recursive_mutex`: 允许同一个线程多次加锁，且该线程需要多次解锁之后，其他线程才能获取该锁  
  b. 大多数时候，递归锁是非必要的  

## 4 并发操作的同步

### 4.1 等待事件或等待其他条件

+ 条件变量  
  a. 条件变量与一个事件或者条件相关联，多个线程可以以其为依托，等待条件成立。  
  b. 当条件成立时，线程会通过该条件变量知会所有等待的线程，唤醒他们继续处理。  
  c. 伪唤醒：当前线程在等待条件变量过程中被唤醒，但是却不是由条件变量的通知而唤醒。  
  d. `std::condition_variable` : 条件变量，需要与互斥锁搭配使用，因为条件属于共享数据，在检查条件是否成立时，需要在锁的保护下进行。  
  e. 条件变量必须搭配`std::unique_lock<>`，因为在条件变量休眠前，需要解锁互斥量，`std::lock_guard<>`没有提供解锁操作。  

  ```C++
  std::condition_variable cond;
  std::mutex mut;
  std::queue q;
  // 线程A
  {
    std::lock_guard<std::mutex> lk(mut);
    q.push(1);
  }
  // 通过条件变量通知其他线程，数据准备好了
  cond.notify_one();

  // 线程B，在获取锁之后检查条件是否成立
  // 如果条件不成立，则释放锁后进入休眠。
  // 如果条件成立，则立即返回
  std::unique_lock<std::mutex> lk(mut);
  cond.wait(lk, [](){
    return !q.empty();
  });
  int data = q.top();
  q.pop();
  lk.unlock();
  process(q);
  ```

### 4.2 使用future做一次性等待

+ `std::future<>` : 通过future，等待任务完成，并获取程序返回值
+ `std::async()` : 和`std::thread`类似，启动一个线程执行任务，并返回一个`future`
+ `std::async()` 有两种启动方式:  
  a. `std::launch::async` : 启动一个新线程执行任务  
  b. `std::launch::deferred` : 延后执行任务，直到在`future`上调用wait时，才开始执行
+ `std::packaged_task<>` : 用于将任务和future绑定，任务用`packaged_task`包装后，可以获取一个`future`对象，而`packaged_task`本身也可以作为一个可调用对象，传递给线程执行。对比`std::async()`的方式，`async()`启动的线程是一次性的，而`packaged_task`对象可以通过一个线程反复执行（线程池）

```C++
template<typename Func>
std::future<void> submit(Func f)
{
    std::packaged_task<void()> task(f);
    std::future<void> res = task.get_future();
    std::lock_guard<std::mutex> lk(mut);
    // task加入任务队列，由任务处理线程去执行。
    tasks.push_back(task);
    return res;
}
```

+ `std::promise<>` : 与一个`std::future<>`对象配对使用  
  a. `future`对象通过`promise`的`get_future()`接口获得  
  b. 当`promise`对象调用`set_value`方法时，`future`可以立即通过get()获得`promise`设置的值  
  c. 简单来说，可以把`promise`看作生产者、`future`看作消费者  
  d. 用于异步传递结果，当一个线程需要异步传递多个结果时，上述两种方法就无法实现。  

+ 如果任务执行过程中抛出异常，则在调用`future.get()`时，也会抛出同样的异常
+ `std::shared_future<>` : `std::future`只允许一个线程等待结果，而`shared_future`可以在多个线程中等待结果  
  a. `shared_future`可以由`future`传入构造函数进行构造，也可以用`future::share()`产生

```C++
std::promise<int> p;
std::shared_future<int> sf = p.get_future().share();
```

### 4.3 限时等待

+ 标准库中的时钟 : `chrono`，标准库中包含多种时钟，每种时钟都包含四种关键信息  
  a. 当前时刻`now()`  
  b. 时间值类型`time_point`  
  c. 计时单元长度`period`，表示为秒的分数形式，例如每秒计数25次，那么计时单元长度就是1/25秒：`std::ratio<1, 25>`  
  d. 计时速率是否恒定`is_steady`，如果计时速率不恒定，那么我们调用两次`now`，返回时间可能不是递增的  

+ 时长类；`std::chrono::duration<>`  
  a. 类模板的第一个参数表示时长的类型，第二个参数是一个分数，表示每个计时单元为多少秒  
  b. `duration<double, ratio<1, 1000>>`表示用double计数的毫秒时长类  
  c. 类型仅仅表示单位，10ms可以用`duration<double, ratio<1, 1000>> ms(10)`表示  

  ```C++
  std::future f = std::async(some_task);
  if (f.wait_for(std::chrono::millseconds(35)) == std::future_status::ready)
      do_something();
  ```

+ 时间点类: `std::chrono::time_point<>`  
  a. 模板参数  
  b. 虽然可以用静态函数std::chrono::system_clock:: to_time_point()转换time_t值，从而求出基于系统时钟的时间点，但其实最“地道”的方法是在程序代码中的某个固定位置，将some_clock::now()和前向偏移相加得出时间点。  

  ```C++
  auto const timeout = std::chrono::steady_clock::now() + std::chrono::millseconds(500);
  std::unique_lock<std::mutex> lk(mut);
  while (!done)
  {
      // 如果此时发生伪唤醒，则需要重新等待500ms
      if (cv.wait_until(lk, timeout) == std::cv_status::timeout)
          break;
  }
  ```

+ `std::this_thread::sleep_until`
+ `std::this_thread::slepp_for`

### 4.4 运用同步操作简化代码

#### 4.4.1 利用future进行函数式编程

+ 函数式编程：术语“函数式编程”（functional programming）是指一种编程风格，函数调用的结果完全取决于参数，而不依赖任何外部状态。  
+ future对象可在线程间传递，所以一个计算任务可以依赖另一个任务的结果，却不必显式地访问共享数据（函数式编程不能依赖共享数据）。
+ `std::async`的实现，可能会判断当前线程数是否过多，而采用同步的方式执行任务

#### 4.4.2 通行式串行进程

+ CSP: 线程相互完全隔离，没有共享数据，采用通信管道传递消息
+ 可以利用状态机实现

#### 4.4.3 后续风格并发

一旦结果数据就绪，就接着进行某项处理  

+ `std::experimental::future`: 基本功能与future一致，但是拥有then方法用于添加后续函数
+ `then`中的任务会在新的线程中执行，不会阻塞主线程
+ `then`中的任务无法指定参数，只能接受唯一一个指定参数，即调用then本身的future
+ 将一个大任务，拆成多个子任务的调用链，可以更高效
+ `std::experimental::shared_future`: 可以对一个`shared_future`添加多个后续函数

#### 4.4.5 等待多个future

+ `std::experimental::when_all`，用于等待多个future全部就绪。
+ 如果我们自己用for循环等到所有future就绪，可能会导致线程在休眠和唤醒间来回切换，从而降低系统性能
+ 例如，future1就绪后唤醒线程，此时future2没有就绪，线程再次休眠，所以会有多次上下文切换
+ `std::experimental::when_any`，用于等待多个future中任意一个future就绪。

上述`std::experimental`的方法作为C++技术规范(TS)，在C++标准中没有被采纳，所以编译器可以不实现

#### 4.4.6 线程闩类

+ `std::latch` : 构造时传入初始计数值，表示需要等待的目标事件次数，每次其他线程完成目标事件时，就会调用线程闩对象的`count_down()`方法减少计数。
主线程使用线程闩对象的`wait()`方法等待线程闩就绪，当计数值为0时，线程闩就绪。
+ 为什么使用线程闩，而不是`future` : future需要等待整个任务完成时才就绪，但是线程闩可以在任意时刻执行`count_down`
+ 线程闩是一个同步对象，`count_down`前的变动，对`wait`后可见
+ 线程闩对象一旦进入就绪状态，就始终保持不变，因此线程闩是一次性的

#### 4.4.7 线程卡类

+ std::barrier : 线程卡用来同步一组线程，同样在构造时传入初始计数值，每个线程都调用线程卡的`arrive_and_wait`方法来等待同步。
当所有线程都到达时，即都调用`arrive_and_wait`时，所有线程同时被唤醒，并继续往下执行。同时线程卡被重置，等待下一轮同步。

```C++
std::barrier sync(threadCnt);
std::vector<std::future<void>> threads;
// 同步一组线程
for (int i = 0; i < threadCnt; i++)
{
    threads.push_back([]{
        while (!done)
        {
        ...
            // 等待所有数据准备好
            sync.arrive_and_wait();
            // 串形区域，
            if (i == 0)
            {
                // 主线程汇总数据
            }
            // 所有线程等待串形区域执行完成
            sync.arrive_and_wait();
        }
    })
}
```

+ std::flex_barrier : 相比于`std::barrier`，`flex_barrier`可以在构造函数中直接设置串形区域执行函数。
只要全部线程都运行到线程卡处，该函数就会在其中一个线程上运行（并且是唯一一个）。并且可以调整线程卡的计数器。

```C++
std::flex_barrier sync(threadCnt, []{
    // 串形区域
});
```

### 4.Q

+ 什么是虚假唤醒?
  a. 通知线程还没有调用通知函数前，接收线程就从等待中唤醒了  
  b. 假设循环中使用的是wait_for()，那么，若在等待时间快消耗完时发生伪唤醒，而我们如果要再次等待，就得重新开始一次完整的迟延等待。这也许会不断重复，令等待变得漫无边际。  
  c. 通过不断循环来处理伪唤醒  

+ 唤醒丢失： 通知线程执行`notify`时，等待线程还没开始执行`wait`，此时通知会丢失，如果不再次执行`notify`，等待线程会一直等待。  

+ 带判断式的wait，可以解决上述两个问题：  
  a. 解决伪唤醒：如果通知线程没有发生通知前，发生伪唤醒的时候，wait函数会再次检查判断式是否为真，如果为真，就认为通知线程发送了通知；否则继续等待通知；  
  b. 解决唤醒丢失：如果通知线程先发生了通知，接收线程后执行wait函数时，会检查判断式是否为真，如果为真，就认为通知线程发送了通知；否则继续等待通知；  
